# app/main.py
# Streamlit UI cho Hybrid RAG: Neo4j (NL2Cypher) + FAISS, ch·∫°y song song v√† hi·ªÉn th·ªã debug chi ti·∫øt
import os
import json
import traceback
import asyncio
import time
from typing import List, Dict, Any

import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

# Local modules
from app.retrievers.hybrid_retriever import HybridRetrieverParallel
from app.retrievers.vector_tools import VectorClient, Passage
from app.utils.hybrid_helpers import (
    load_answer_rule,
    build_id_map_from_graph_records,
    select_topN_by_priority,
    build_synthesis_input,
    llm_summarize_answer,
)


# C·∫•u h√¨nh h·ªá th·ªëng
load_dotenv()

def get_var(key, default=None, section="general"):
    try:
        return st.secrets[section].get(key, default)
    except Exception:
        return os.getenv(key, default)

OPENAI_MODEL = get_var("OPENAI_MODEL", "gpt-4o-mini")
ANSWER_RULE_PATH = get_var("ANSWER_RULE_PATH", "app/prompts/answer_synthesis.txt")
OPENAI_API_KEY = get_var("OPENAI_API_KEY")
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
client = OpenAI(api_key=OPENAI_API_KEY)



# Giao di·ªán ch√≠nh
def main():
    st.set_page_config(page_title="Hybrid RAG - B·∫•t ƒë·ªông s·∫£n H√† N·ªôi", page_icon="üè†", layout="wide")
    st.title("üè† Hybrid RAG cho B·∫•t ƒë·ªông s·∫£n H√† N·ªôi (Parallel)")
    st.caption("K·∫øt h·ª£p Neo4j (Graph) + FAISS (Vector) ¬∑ Ch·∫°y song song ¬∑ T·ªïng h·ª£p b·∫±ng GPT")

    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
        model = st.text_input("OPENAI_MODEL", value=OPENAI_MODEL)
        top_k = st.slider("S·ªë k·∫øt qu·∫£ Vector (k)", min_value=5, max_value=20, value=10)
        limit_ids = st.slider("Gi·ªõi h·∫°n ID tr·∫£ l·ªùi", min_value=1, max_value=5, value=3)
        show_debug = st.checkbox("üß© Hi·ªÉn th·ªã debug (IDs & m√¥ t·∫£)", value=True)

    # Input
    user_query = st.text_input(
        "üí¨ Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:",
        placeholder="V√≠ d·ª•: T√¨m nh√† 5 t·∫ßng s·ªï ƒë·ªè ch√≠nh ch·ªß t·∫°i Thanh Xu√¢n"
    )
    run = st.button("üîé T√¨m ki·∫øm")


    # X·ª≠ l√Ω khi ng∆∞·ªùi d√πng nh·∫•n t√¨m ki·∫øm
    if run and user_query.strip():
        try:
            client = OpenAI(api_key=OPENAI_API_KEY)
            synth_rule = load_answer_rule()
            hybrid = HybridRetrieverParallel()
            vclient = hybrid.vector

            # 1 Ch·∫°y truy v·∫•n song song Graph + Vector
            st.info("‚è≥ ƒêang truy v·∫•n d·ªØ li·ªáu song song t·ª´ Neo4j v√† FAISS...")
            start = time.time()
            hybrid_result = asyncio.run(hybrid.search(user_query=user_query, top_k=top_k))
            took = int((time.time() - start) * 1000)

            graph_records = hybrid_result["graph_records"]
            graph_ids = hybrid_result["graph_ids"]
            vector_passages = hybrid_result["vector_passages"]

            # üìú Hi·ªÉn th·ªã Cypher Query n·∫øu c√≥
            if "cypher_query" in hybrid_result and hybrid_result["cypher_query"]:
                st.markdown("---")
                st.subheader("üìú Truy v·∫•n Cypher ƒë∆∞·ª£c sinh ra")
                st.code(hybrid_result["cypher_query"], language="cypher")


            # 2 K·∫øt h·ª£p d·ªØ li·ªáu
            graph_id_map = build_id_map_from_graph_records(graph_records)
            chosen_passages = select_topN_by_priority(
                graph_ids, vector_passages, vclient, graph_id_map, fill_limit=limit_ids
            )


            # Debug
            if show_debug:
                st.markdown("---")
                st.subheader("üß© DEBUG TH√îNG TIN")

                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("üìä IDs t·ª´ Graph")
                    st.write(graph_ids[:20])
                with col2:
                    st.subheader("üìö IDs trong Vector (t·ª´ k k·∫øt qu·∫£)")
                    st.write([p.id for p in vector_passages if p.id][:20])

                st.subheader("‚úÖ ID ƒë∆∞·ª£c ch·ªçn (∆∞u ti√™n tr√πng, t·ªëi ƒëa N)")
                st.write([p.id for p in chosen_passages])

                st.subheader("üìù Snippet m√¥ t·∫£ (Vector)")
                for p in chosen_passages:
                    st.markdown(
                        f"- **ID {p.id or 'N/A'}** ¬∑ _{(p.text or '')[:200]}{'...' if p.text and len(p.text)>200 else ''}_"
                    )

                st.info(f"‚è± T·ªïng th·ªùi gian truy v·∫•n song song: **{took} ms**")

            # 3 Chu·∫©n b·ªã d·ªØ li·ªáu cho LLM
            synthesis_payload = build_synthesis_input(chosen_passages, graph_id_map)

            # 4 G·ªçi LLM ƒë·ªÉ t·ªïng h·ª£p c√¢u tr·∫£ l·ªùi
            st.write("üß† ƒêang t·ªïng h·ª£p c√¢u tr·∫£ l·ªùi...")
            answer = llm_summarize_answer(client, user_query, synth_rule, synthesis_payload, model)

            # 5 Hi·ªÉn th·ªã k·∫øt qu·∫£
            st.markdown("---")
            st.subheader("‚ú® C√¢u tr·∫£ l·ªùi")
            st.write(answer)

            # 6 B·∫£ng d·ªØ li·ªáu chi ti·∫øt
            with st.expander("üìã Xem d·ªØ li·ªáu ƒë√£ h·ª£p nh·∫•t (debug)"):
                merged_rows = []
                for p in chosen_passages:
                    pid = str(p.id).strip() if p.id else None
                    row = {"id": pid, "text_len": len(p.text or "")}
                    row.update(graph_id_map.get(pid, {}))
                    merged_rows.append(row)
                try:
                    import pandas as pd
                    st.dataframe(pd.DataFrame(merged_rows))
                except Exception:
                    st.json(merged_rows)

        except Exception as e:
            st.error("‚ùå L·ªói khi x·ª≠ l√Ω truy v·∫•n.")
            st.exception(e)
            st.text(traceback.format_exc())

    # Footer
    st.markdown("---")
    st.caption("¬© Hybrid RAG ‚Ä¢ Neo4j + FAISS ‚Ä¢ Ch·∫°y song song b·∫±ng asyncio")


if __name__ == "__main__":
    main()
